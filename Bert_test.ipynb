{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1016 17:12:11.381353  4948 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at C:\\Users\\Grace\\.cache\\torch\\transformers\\5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    }
   ],
   "source": [
    "PRETRAINED_MODEL_NAME = \"bert-base-cased\"  # 指定英文的 BERT-BASE 預訓練模型\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 簡單的數據清理，去除空白標題的 examples\n",
    "df_train = pd.read_csv(\"task1_trainset.csv\")\n",
    "\n",
    "empty_title = ((df_train['Authors'].isnull()) \\\n",
    "\t\t\t   | (df_train['Categories'].isnull()) \\\n",
    "\t\t\t   | (df_train['Created Date'].isnull()))\n",
    "df_train = df_train[~empty_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>Task 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D00001</td>\n",
       "      <td>A Brain-Inspired Trust Management Model to Ass...</td>\n",
       "      <td>Rapid popularity of Internet of Things (IoT) a...</td>\n",
       "      <td>Mahmud/Kaiser/Rahman/Rahman/Shabut/Al-Mamun/Hu...</td>\n",
       "      <td>cs.CR/cs.AI/q-bio.NC</td>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>BACKGROUND OBJECTIVES METHODS METHODS RESULTS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D00002</td>\n",
       "      <td>On Efficient Computation of Shortest Dubins Pa...</td>\n",
       "      <td>In this paper, we address the problem of compu...</td>\n",
       "      <td>Sadeghi/Smith</td>\n",
       "      <td>cs.SY/cs.RO/math.OC</td>\n",
       "      <td>2016-09-21</td>\n",
       "      <td>OBJECTIVES OTHERS METHODS/RESULTS RESULTS RESULTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D00003</td>\n",
       "      <td>Data-driven Upsampling of Point Clouds</td>\n",
       "      <td>High quality upsampling of sparse 3D point clo...</td>\n",
       "      <td>Zhang/Jiang/Yang/Yamakawa/Shimada/Kara</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2018-07-07</td>\n",
       "      <td>BACKGROUND OBJECTIVES METHODS METHODS METHODS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D00004</td>\n",
       "      <td>Accessibility or Usability of InteractSE? A He...</td>\n",
       "      <td>Internet is the main source of information now...</td>\n",
       "      <td>Aqle/Khowaja/Al-Thani</td>\n",
       "      <td>cs.HC</td>\n",
       "      <td>2018-08-29</td>\n",
       "      <td>BACKGROUND BACKGROUND BACKGROUND OBJECTIVES OB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D00005</td>\n",
       "      <td>Spatio-Temporal Facial Expression Recognition ...</td>\n",
       "      <td>Automated Facial Expression Recognition (FER) ...</td>\n",
       "      <td>Hasani/Mahoor</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>BACKGROUND BACKGROUND BACKGROUND BACKGROUND ME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D00006</td>\n",
       "      <td>Continuous Semantic Topic Embedding Model Usin...</td>\n",
       "      <td>This paper proposes the continuous semantic to...</td>\n",
       "      <td>Jung/Choi</td>\n",
       "      <td>stat.ML/cs.CL/cs.LG</td>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>OBJECTIVES/METHODS METHODS CONCLUSIONS RESULTS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D00007</td>\n",
       "      <td>Beyond Shared Hierarchies: Deep Multitask Lear...</td>\n",
       "      <td>Existing deep multitask learning (MTL) approac...</td>\n",
       "      <td>Meyerson/Miikkulainen</td>\n",
       "      <td>cs.LG/cs.AI/stat.ML</td>\n",
       "      <td>2017-10-31</td>\n",
       "      <td>BACKGROUND BACKGROUND/OBJECTIVES OBJECTIVES/ME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D00008</td>\n",
       "      <td>Using Scalp Electrical Biosignals to Control a...</td>\n",
       "      <td>In this paper we explore the use of electrical...</td>\n",
       "      <td>George/Lotte/Abad/Lécuyer</td>\n",
       "      <td>cs.OH</td>\n",
       "      <td>2011-11-08</td>\n",
       "      <td>OBJECTIVES METHODS METHODS METHODS METHODS RES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D00009</td>\n",
       "      <td>Robustness from structure: Inference with hier...</td>\n",
       "      <td>How spiking networks are able to perform proba...</td>\n",
       "      <td>Petrovici/Schroeder/Breitwieser/Grübl/Schemmel...</td>\n",
       "      <td>q-bio.NC/cs.NE/stat.ML</td>\n",
       "      <td>2017-03-12</td>\n",
       "      <td>BACKGROUND/OBJECTIVES BACKGROUND BACKGROUND/ME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D00010</td>\n",
       "      <td>Statistical Mechanical Analysis of Low-Density...</td>\n",
       "      <td>Low-density parity-check (LDPC) codes on symme...</td>\n",
       "      <td>Mori/Tanaka</td>\n",
       "      <td>cs.IT/math.IT</td>\n",
       "      <td>2011-10-10</td>\n",
       "      <td>BACKGROUND OBJECTIVES RESULTS/CONCLUSIONS METHODS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                              Title  \\\n",
       "0  D00001  A Brain-Inspired Trust Management Model to Ass...   \n",
       "1  D00002  On Efficient Computation of Shortest Dubins Pa...   \n",
       "2  D00003             Data-driven Upsampling of Point Clouds   \n",
       "3  D00004  Accessibility or Usability of InteractSE? A He...   \n",
       "4  D00005  Spatio-Temporal Facial Expression Recognition ...   \n",
       "5  D00006  Continuous Semantic Topic Embedding Model Usin...   \n",
       "6  D00007  Beyond Shared Hierarchies: Deep Multitask Lear...   \n",
       "7  D00008  Using Scalp Electrical Biosignals to Control a...   \n",
       "8  D00009  Robustness from structure: Inference with hier...   \n",
       "9  D00010  Statistical Mechanical Analysis of Low-Density...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Rapid popularity of Internet of Things (IoT) a...   \n",
       "1  In this paper, we address the problem of compu...   \n",
       "2  High quality upsampling of sparse 3D point clo...   \n",
       "3  Internet is the main source of information now...   \n",
       "4  Automated Facial Expression Recognition (FER) ...   \n",
       "5  This paper proposes the continuous semantic to...   \n",
       "6  Existing deep multitask learning (MTL) approac...   \n",
       "7  In this paper we explore the use of electrical...   \n",
       "8  How spiking networks are able to perform proba...   \n",
       "9  Low-density parity-check (LDPC) codes on symme...   \n",
       "\n",
       "                                             Authors              Categories  \\\n",
       "0  Mahmud/Kaiser/Rahman/Rahman/Shabut/Al-Mamun/Hu...    cs.CR/cs.AI/q-bio.NC   \n",
       "1                                      Sadeghi/Smith     cs.SY/cs.RO/math.OC   \n",
       "2             Zhang/Jiang/Yang/Yamakawa/Shimada/Kara                   cs.CV   \n",
       "3                              Aqle/Khowaja/Al-Thani                   cs.HC   \n",
       "4                                      Hasani/Mahoor                   cs.CV   \n",
       "5                                          Jung/Choi     stat.ML/cs.CL/cs.LG   \n",
       "6                              Meyerson/Miikkulainen     cs.LG/cs.AI/stat.ML   \n",
       "7                          George/Lotte/Abad/Lécuyer                   cs.OH   \n",
       "8  Petrovici/Schroeder/Breitwieser/Grübl/Schemmel...  q-bio.NC/cs.NE/stat.ML   \n",
       "9                                        Mori/Tanaka           cs.IT/math.IT   \n",
       "\n",
       "  Created Date                                             Task 1  \n",
       "0   2018-01-11  BACKGROUND OBJECTIVES METHODS METHODS RESULTS ...  \n",
       "1   2016-09-21  OBJECTIVES OTHERS METHODS/RESULTS RESULTS RESULTS  \n",
       "2   2018-07-07  BACKGROUND OBJECTIVES METHODS METHODS METHODS ...  \n",
       "3   2018-08-29  BACKGROUND BACKGROUND BACKGROUND OBJECTIVES OB...  \n",
       "4   2017-03-20  BACKGROUND BACKGROUND BACKGROUND BACKGROUND ME...  \n",
       "5   2017-11-24  OBJECTIVES/METHODS METHODS CONCLUSIONS RESULTS...  \n",
       "6   2017-10-31  BACKGROUND BACKGROUND/OBJECTIVES OBJECTIVES/ME...  \n",
       "7   2011-11-08  OBJECTIVES METHODS METHODS METHODS METHODS RES...  \n",
       "8   2017-03-12  BACKGROUND/OBJECTIVES BACKGROUND BACKGROUND/ME...  \n",
       "9   2011-10-10  BACKGROUND OBJECTIVES RESULTS/CONCLUSIONS METHODS  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 去除不必要的欄位並重新命名兩標題的欄位名\n",
    "df_train = df_train.reset_index()\n",
    "df_train = df_train.loc[:, ['Abstract', 'Task 1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Abstract_snt_list = []\n",
    "label_snt_list = []\n",
    "for data in df_train['Abstract']:\n",
    "    data = data.split('$$$')\n",
    "    #一句一句話分離\n",
    "    for snt in data:\n",
    "        Abstract_snt_list.append(snt)\n",
    "for label in df_train['Task 1']:\n",
    "    label = label.split(\" \")\n",
    "    for la in label:\n",
    "        label_snt_list.append(la.split(\"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rapid popularity of Internet of Things (IoT) and cloud computing permits neuroscientists to collect multilevel and multichannel brain data to better understand brain functions, diagnose diseases, and devise treatments.',\n",
       " 'To ensure secure and reliable data communication between end-to-end (E2E) devices supported by current IoT and cloud infrastructure, trust management is needed at the IoT and user ends.',\n",
       " 'This paper introduces a Neuro-Fuzzy based Brain-inspired trust management model (TMM) to secure IoT devices and relay nodes, and to ensure data reliability.',\n",
       " 'The proposed TMM utilizes node behavioral trust and data trust estimated using Adaptive Neuro-Fuzzy Inference System and weighted-additive methods respectively to assess the nodes trustworthiness.',\n",
       " 'In contrast to the existing fuzzy based TMMs, the NS2 simulation results confirm the robustness and accuracy of the proposed TMM in identifying malicious nodes in the communication network.',\n",
       " 'With the growing usage of cloud based IoT frameworks in Neuroscience research, integrating the proposed TMM into the existing infrastructure will assure secure and reliable data communication among the E2E devices.',\n",
       " 'In this paper, we address the problem of computing optimal paths through three consecutive points for the curvature-constrained forward moving Dubins vehicle.',\n",
       " 'Given initial and final configurations of the Dubins vehicle, and a midpoint with an unconstrained heading, the objective is to compute the midpoint heading that minimizes the total Dubins path length.',\n",
       " \"We provide a novel geometrical analysis of the optimal path, and establish new properties of the optimal Dubins' path through three points.\",\n",
       " 'We then show how our method can be used to quickly refine Dubins TSP tours produced using state-of-the-art techniques.']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Abstract_snt_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['BACKGROUND'],\n",
       " ['OBJECTIVES'],\n",
       " ['METHODS'],\n",
       " ['METHODS'],\n",
       " ['RESULTS'],\n",
       " ['CONCLUSIONS'],\n",
       " ['OBJECTIVES'],\n",
       " ['OTHERS'],\n",
       " ['METHODS', 'RESULTS'],\n",
       " ['RESULTS']]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_snt_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abstract_dict = {\n",
    "    'text': Abstract_snt_list,\n",
    "    'label': label_snt_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(abstract_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rapid popularity of Internet of Things (IoT) a...</td>\n",
       "      <td>[BACKGROUND]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To ensure secure and reliable data communicati...</td>\n",
       "      <td>[OBJECTIVES]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This paper introduces a Neuro-Fuzzy based Brai...</td>\n",
       "      <td>[METHODS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The proposed TMM utilizes node behavioral trus...</td>\n",
       "      <td>[METHODS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In contrast to the existing fuzzy based TMMs, ...</td>\n",
       "      <td>[RESULTS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>With the growing usage of cloud based IoT fram...</td>\n",
       "      <td>[CONCLUSIONS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In this paper, we address the problem of compu...</td>\n",
       "      <td>[OBJECTIVES]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Given initial and final configurations of the ...</td>\n",
       "      <td>[OTHERS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We provide a novel geometrical analysis of the...</td>\n",
       "      <td>[METHODS, RESULTS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We then show how our method can be used to qui...</td>\n",
       "      <td>[RESULTS]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               label\n",
       "0  Rapid popularity of Internet of Things (IoT) a...        [BACKGROUND]\n",
       "1  To ensure secure and reliable data communicati...        [OBJECTIVES]\n",
       "2  This paper introduces a Neuro-Fuzzy based Brai...           [METHODS]\n",
       "3  The proposed TMM utilizes node behavioral trus...           [METHODS]\n",
       "4  In contrast to the existing fuzzy based TMMs, ...           [RESULTS]\n",
       "5  With the growing usage of cloud based IoT fram...       [CONCLUSIONS]\n",
       "6  In this paper, we address the problem of compu...        [OBJECTIVES]\n",
       "7  Given initial and final configurations of the ...            [OTHERS]\n",
       "8  We provide a novel geometrical analysis of the...  [METHODS, RESULTS]\n",
       "9  We then show how our method can be used to qui...           [RESULTS]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rapid popularity of Internet of Things (IoT) a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To ensure secure and reliable data communicati...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This paper introduces a Neuro-Fuzzy based Brai...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The proposed TMM utilizes node behavioral trus...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In contrast to the existing fuzzy based TMMs, ...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>With the growing usage of cloud based IoT fram...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In this paper, we address the problem of compu...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Given initial and final configurations of the ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We provide a novel geometrical analysis of the...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>We then show how our method can be used to qui...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Rapid popularity of Internet of Things (IoT) a...      0\n",
       "1  To ensure secure and reliable data communicati...     21\n",
       "2  This paper introduces a Neuro-Fuzzy based Brai...     17\n",
       "3  The proposed TMM utilizes node behavioral trus...     17\n",
       "4  In contrast to the existing fuzzy based TMMs, ...     30\n",
       "5  With the growing usage of cloud based IoT fram...     16\n",
       "6  In this paper, we address the problem of compu...     21\n",
       "7  Given initial and final configurations of the ...     29\n",
       "8  We provide a novel geometrical analysis of the...     19\n",
       "9  We then show how our method can be used to qui...     30"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "data_le = pd.DataFrame(abstract_dict)\n",
    "data_le['label'] = labelencoder.fit_transform(X['label'])\n",
    "data_le[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D', 'E', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N',\n",
       "       'O', 'R', 'S', 'T', 'U', 'V'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create MultiLabelBinarizer object\n",
    "one_hot = MultiLabelBinarizer()\n",
    "#data_one_hot = pd.DataFrame(abstract_dict)\n",
    "#data_one_hot.label = one_hot.fit_transform(X.label)\n",
    "# One-hot encode data\n",
    "X_one_hot = one_hot.fit(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVES', 'OTHERS',\n",
    "       'RESULTS'])\n",
    "#test = X_one_hot.transform(X.label)\n",
    "#X_one_hot = one_hot.fit_transform(X.label)\n",
    "'''\n",
    "s = X['label']\n",
    "one_hot = MultiLabelBinarizer()\n",
    "X_one_hot = pd.DataFrame(one_hot.fit_transform(s),columns=one_hot.classes_, index=X.index)\n",
    "'''\n",
    "# View classes\n",
    "one_hot.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_one_hot = X.label.str.join('|').str.get_dummies().add_prefix('')\n",
    "df = pd.concat([X,data_one_hot],axis=1).drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = df.loc[:10,['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVES', 'OTHERS','RESULTS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[8,['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVES', 'OTHERS','RESULTS']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.loc[8,['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVES', 'OTHERS','RESULTS']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test.csv的處理\n",
    "df_test = pd.read_csv(\"task1_public_testset.csv\")\n",
    "df_test = df_test.loc[:, ['Abstract', \"Id\"]]\n",
    "df_test.columns = [\"text\", \"Id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RangeIndex' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-98f2c34e5f52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'RangeIndex' object is not callable"
     ]
    }
   ],
   "source": [
    "for data in df_test[\"text\"]:\n",
    "    print(df_test.loc[df_test['text'].index(data),'Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1016 18:18:31.422483  4948 tokenization_utils.py:373] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at C:\\Users\\Grace\\.cache\\torch\\transformers\\5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練樣本數： 46867\n",
      "Index(['text', 'BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVES', 'OTHERS',\n",
      "       'RESULTS'],\n",
      "      dtype='object')\n",
      "                                                text  BACKGROUND  CONCLUSIONS  \\\n",
      "0  Rapid popularity of Internet of Things (IoT) a...           1            0   \n",
      "1  To ensure secure and reliable data communicati...           0            0   \n",
      "2  This paper introduces a Neuro-Fuzzy based Brai...           0            0   \n",
      "3  The proposed TMM utilizes node behavioral trus...           0            0   \n",
      "4  In contrast to the existing fuzzy based TMMs, ...           0            0   \n",
      "\n",
      "   METHODS  OBJECTIVES  OTHERS  RESULTS  \n",
      "0        0           0       0        0  \n",
      "1        0           1       0        0  \n",
      "2        1           0       0        0  \n",
      "3        1           0       0        0  \n",
      "4        0           0       0        1  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer\n",
    "import random\n",
    "\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-cased\"  # 指定英文的 BERT-BASE 預訓練模型\n",
    "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "###----1. 準備原始文本數據\n",
    "\n",
    "def data_preprocessing(csv_name,mode):\n",
    "\tdf = pd.read_csv(csv_name)\n",
    "\tempty_title = ((df['Authors'].isnull()) \\\n",
    "\t\t\t   | (df['Categories'].isnull()) \\\n",
    "\t\t\t   | (df['Created Date'].isnull()))\n",
    "\tdf = df[~empty_title]\n",
    "\n",
    "\t#重設columns\n",
    "\tdf = df.reset_index()\n",
    "\tif mode=='train':\n",
    "\t\tdf = df.loc[:, ['Abstract', 'Task 1']]\n",
    "\t\tdf.columns = ['text', 'label']\n",
    "\telse:\n",
    "\t\tdf_test = df_test.loc[:, ['Abstract', \"Id\"]]\n",
    "\t\tdf_test.columns = [\"text\", \"Id\"]\n",
    "\n",
    "\t#將abstract內每句話和label分離\n",
    "\tAbstract_snt_list = []\n",
    "\tlabel_snt_list = []\n",
    "\tid_snt_list = []\n",
    "\tfor data in df['text']:\n",
    "\t\tdata = data.split('$$$')\n",
    "\t\t#一句一句話分離\n",
    "\t\tfor snt in data:\n",
    "\t\t\tAbstract_snt_list.append(snt)\n",
    "\t\t'''\n",
    "\t\t#還沒改好test部分\n",
    "\t\tif mode=='test':\n",
    "\t\t\tid_snt_list.append()\n",
    "\t\t\tabstract_dict = {\n",
    "\t\t\t\t'text': Abstract_snt_list,\n",
    "\t\t\t\t'id': label_snt_list\n",
    "\t\t\t}\n",
    "\t\t\t'''\n",
    "\tif mode=='train':\n",
    "\t\tfor label in df['label']:\n",
    "\t\t\tlabel = label.split(\" \")\n",
    "\t\t\tfor la in label:\n",
    "\t\t\t\tlabel_snt_list.append(la.split(\"/\"))\n",
    "\t\tabstract_dict = {\n",
    "\t\t'text': Abstract_snt_list,\n",
    "\t\t'label': label_snt_list\n",
    "\t\t}\n",
    "\n",
    "\treturn abstract_dict\n",
    "\n",
    "def one_hot_encoding(X):\t#對多標籤進行one hot encoding\n",
    "\tdata_one_hot = X.label.str.join('|').str.get_dummies().add_prefix('')\t#one hot encoding 後將結果併入原dataframe\n",
    "\tdf = pd.concat([X,data_one_hot],axis=1).drop(['label'],axis=1)\t#去除未轉換前的label\n",
    "\treturn df\n",
    "\n",
    "\n",
    "#轉成dataframe並進行ont hot encoding後存起來\n",
    "abstract_dict = data_preprocessing('task1_trainset.csv','train')\n",
    "df_train = pd.DataFrame(abstract_dict)\n",
    "df_train = one_hot_encoding(df_train)\n",
    "df_train.to_csv(\"task1_trainset.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"訓練樣本數：\", len(df_train))\n",
    "print(df_train.columns)\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pysnooper\n",
    " \n",
    "\t\n",
    "class PaperDataset(Dataset):\n",
    "\t# 讀取前處理後的 tsv 檔並初始化一些參數\n",
    "\tdef __init__(self, mode, tokenizer):\n",
    "\t\tassert mode in [\"task1_trainset\", \"task1_public_testset\"]  # 一般訓練你會需要 dev set\n",
    "\t\tself.mode = mode\n",
    "\t\t# 大數據你會需要用 iterator=True\n",
    "\t\tself.df = pd.read_csv(mode + \".tsv\", sep=\"\\t\").fillna(\"\")\n",
    "\t\tself.len = len(self.df)\n",
    "\t\t#self.label_map = {'BACKGROUND': 0, 'OBJECTIVES': 1, 'METHODS': 2, 'RESULTS': 3, 'CONCLUSIONS': 4, 'OTHERS': 5}\n",
    "\t\tself.tokenizer = tokenizer  # 我們將使用 BERT tokenizer\n",
    "\t# 定義回傳一筆訓練 / 測試數據的函式\n",
    "\tdef __getitem__(self, idx):\t#Called to implement evaluation of self[key] (special method in python)\n",
    "\t\tif self.mode == \"task1_public_testset\":\n",
    "\t\t\ttext = self.df.iloc[idx, :1].values #把dataframe每行資料的前兩個col取出，也就是把text_a和text_b單獨取出來\n",
    "\t\t\tlabel_tensor = None\n",
    "\t\telse:\n",
    "\t\t\ttext= self.df.iloc[idx, :1].values\n",
    "\t\t\tlabel_id = list(self.df.loc[idx,['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVES', 'OTHERS','RESULTS']])\n",
    "\t\t\tlabel_tensor = torch.FloatTensor(label_id)\n",
    "\t\t\n",
    "\t\t#建立句子的 BERT tokens 並加入分隔符號 [SEP]\n",
    "\t\t# 建立第一個(Title)句子的 BERT tokens 並加入分隔符號 [SEP]\n",
    "\t\tword_pieces = [\"[CLS]\"]\n",
    "\t\ttokens = self.tokenizer.tokenize(str(text[0]))\n",
    "\t\tword_pieces += tokens + [\"[SEP]\"]\n",
    "\t\tlen_tokens = len(word_pieces)\n",
    "\n",
    "\t\t# 將整個 token 序列轉換成索引序列\n",
    "\t\tids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "\t\ttokens_tensor = torch.tensor(ids)\n",
    "\t\t\n",
    "\t\t# 將abstract包含 [SEP] 的 token 位置設為 1, 0 為pedding\n",
    "\t\tsegments_tensor = torch.tensor([0] * len_tokens,\n",
    "\t\t\t\t\t\t\t\t\t\tdtype=torch.long)\n",
    "\t\t\n",
    "\t\treturn (tokens_tensor, segments_tensor, label_tensor)\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.len\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = df.iloc[0, :1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rapid popularity of Internet of Things (IoT) and cloud computing permits neuroscientists to collect multilevel and multichannel brain data to better understand brain functions, diagnose diseases, and devise treatments.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rapid',\n",
       " 'popularity',\n",
       " 'of',\n",
       " 'Internet',\n",
       " 'of',\n",
       " 'Things',\n",
       " '(',\n",
       " 'I',\n",
       " '##o',\n",
       " '##T',\n",
       " ')',\n",
       " 'and',\n",
       " 'cloud',\n",
       " 'computing',\n",
       " 'permits',\n",
       " 'ne',\n",
       " '##uro',\n",
       " '##s',\n",
       " '##cie',\n",
       " '##nti',\n",
       " '##sts',\n",
       " 'to',\n",
       " 'collect',\n",
       " 'multi',\n",
       " '##lev',\n",
       " '##el',\n",
       " 'and',\n",
       " 'multi',\n",
       " '##chan',\n",
       " '##nel',\n",
       " 'brain',\n",
       " 'data',\n",
       " 'to',\n",
       " 'better',\n",
       " 'understand',\n",
       " 'brain',\n",
       " 'functions',\n",
       " ',',\n",
       " 'di',\n",
       " '##ag',\n",
       " '##nose',\n",
       " 'diseases',\n",
       " ',',\n",
       " 'and',\n",
       " 'de',\n",
       " '##vise',\n",
       " 'treatments',\n",
       " '.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(str(text[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\t\n",
    "# 初始化一個專門讀取訓練樣本的 Dataset，使用英文 BERT 斷詞\n",
    "trainset = PaperDataset(\"task1_trainset\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[原始文本]\n",
      "句子 1：Rapid popularity of Internet of Things (IoT) and cloud computing permits neuroscientists to collect multilevel and multichannel brain data to better understand brain functions, diagnose diseases, and devise treatments.\n",
      "分類  ：[]\n",
      "\n",
      "--------------------\n",
      "\n",
      "[Dataset 回傳的 tensors]\n",
      "tokens_tensor  ：tensor([  101, 16356,  5587,  1104,  4639,  1104,  7149,   113,   146,  1186,\n",
      "         1942,   114,  1105,  7180, 12783, 15267, 24928, 11955,  1116, 25982,\n",
      "        14964, 10047,  1106,  7822,  4321, 23403,  1883,  1105,  4321, 18546,\n",
      "         8967,  3575,  2233,  1106,  1618,  2437,  3575,  4226,   117,  4267,\n",
      "         8517, 22583,  8131,   117,  1105,  1260, 16641, 14115,   119,   102])\n",
      "\n",
      "segments_tensor：tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0])\n",
      "\n",
      "label_tensor   ：tensor([1., 0., 0., 0., 0., 0.])\n",
      "\n",
      "--------------------\n",
      "\n",
      "[還原 tokens_tensors]\n",
      "[CLS] Rapid popularity of Internet of Things ( I ##o ##T ) and cloud computing permits ne ##uro ##s ##cie ##nti ##sts to collect multi ##lev ##el and multi ##chan ##nel brain data to better understand brain functions , di ##ag ##nose diseases , and de ##vise treatments . [SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 選擇第一個樣本\n",
    "sample_idx = 0\n",
    "\n",
    "# 將原始文本拿出做比較\n",
    "abstract = trainset.df['text'][sample_idx]\n",
    "label = trainset.df.iloc[sample_idx,7:].values\n",
    "\n",
    "# 利用剛剛建立的 Dataset 取出轉換後的 id tensors\n",
    "tokens_tensor, segments_tensor, label_tensor = trainset[sample_idx]\n",
    "\n",
    "# 將 tokens_tensor 還原成文本\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
    "combined_text = \" \".join(tokens)\n",
    "\n",
    "# 渲染前後差異，毫無反應就是個 print。可以直接看輸出結果\n",
    "print(f\"\"\"[原始文本]\n",
    "句子 1：{abstract}\n",
    "分類  ：{label}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[Dataset 回傳的 tensors]\n",
    "tokens_tensor  ：{tokens_tensor}\n",
    "\n",
    "segments_tensor：{segments_tensor}\n",
    "\n",
    "label_tensor   ：{label_tensor}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[還原 tokens_tensors]\n",
    "{combined_text}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rapid popularity of Internet of Things (IoT) and cloud computing permits neuroscientists to collect multilevel and multichannel brain data to better understand brain functions, diagnose diseases, and devise treatments.',\n",
       "       1, 0, 0, 0, 0, 0], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.df.iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# 這個函式的輸入 `samples` 是一個 list，裡頭的每個 element 都是\n",
    "# 剛剛定義的 `PaperDataset` 回傳的一個樣本，每個樣本都包含 3 tensors：\n",
    "# - tokens_tensor\n",
    "# - segments_tensor\n",
    "# - label_tensor\n",
    "# 它會對前兩個 tensors 作 zero padding，並產生前面說明過的 masks_tensors\n",
    "def create_mini_batch(samples):\n",
    "\ttokens_tensors = [s[0] for s in samples]\n",
    "\tsegments_tensors = [s[1] for s in samples]\n",
    "\t\n",
    "\t# 取第一個element 內看看它的label_tensor是否為None，若為None代表是測試集\n",
    "\tif samples[0][2] is not None:\n",
    "\t\t#torch.stack: 沿着一个新维度对输入张量序列进行连接。 序列中所有的张量都应该为相同形状。\n",
    "\t\tlabel_ids = torch.stack([s[2] for s in samples]) # 將m1和m2兩個矩陣在新的維度（第一維）疊起來\n",
    "\t\t#label_ids = [s[2] for s in samples]\n",
    "\telse:\n",
    "\t\tlabel_ids = None\n",
    "\t\n",
    "\t# zero pad 到同一序列長度\n",
    "\ttokens_tensors = pad_sequence(tokens_tensors, \n",
    "\t\t\t\t\t\t\t\t  batch_first=True)\n",
    "\tsegments_tensors = pad_sequence(segments_tensors, \n",
    "\t\t\t\t\t\t\t\t\tbatch_first=True)\n",
    "\t\n",
    "\t# attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
    "\t# 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
    "\tmasks_tensors = torch.zeros(tokens_tensors.shape, \n",
    "\t\t\t\t\t\t\t\tdtype=torch.long)\n",
    "\tmasks_tensors = masks_tensors.masked_fill(\n",
    "\t\ttokens_tensors != 0, 1)\n",
    "\t\n",
    "\treturn tokens_tensors, segments_tensors, masks_tensors, label_ids\n",
    "\n",
    "\n",
    "# 初始化一個每次回傳 64 個訓練樣本的 DataLoader﹝因為不可能一次把整個數據集放入GPU﹞\n",
    "# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch 是關鍵\n",
    "# `collate_fn` merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset.\n",
    "# `batch_size`: how many samples per batch to load (default: 1).\n",
    "BATCH_SIZE = 64\n",
    "# DataLoader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, \n",
    "\t\t\t\t\t\t collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tokens_tensors.shape   = torch.Size([64, 86]) \n",
      "tensor([[  101, 16356,  5587,  ...,     0,     0,     0],\n",
      "        [  101,  1706,  4989,  ...,     0,     0,     0],\n",
      "        [  101,  1188,  2526,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1109,  1648,  ...,     0,     0,     0],\n",
      "        [  101, 16005,  1437,  ...,     0,     0,     0],\n",
      "        [  101, 12859, 20913,  ...,     0,     0,     0]])\n",
      "------------------------\n",
      "segments_tensors.shape = torch.Size([64, 86])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "------------------------\n",
      "masks_tensors.shape    = torch.Size([64, 86])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "------------------------\n",
      "label_ids.shape        = torch.Size([64, 6])\n",
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 1.],\n",
      "        [0., 0., 1., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "data = next(iter(trainloader))\n",
    "\n",
    "tokens_tensors, segments_tensors, \\\n",
    "    masks_tensors, label_ids = data\n",
    "\n",
    "print(f\"\"\"\n",
    "tokens_tensors.shape   = {tokens_tensors.shape} \n",
    "{tokens_tensors}\n",
    "------------------------\n",
    "segments_tensors.shape = {segments_tensors.shape}\n",
    "{segments_tensors}\n",
    "------------------------\n",
    "masks_tensors.shape    = {masks_tensors.shape}\n",
    "{masks_tensors}\n",
    "------------------------\n",
    "label_ids.shape        = {label_ids.shape}\n",
    "{label_ids}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1016 20:16:42.064945  4948 configuration_utils.py:151] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at C:\\Users\\Grace\\.cache\\torch\\transformers\\b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I1016 20:16:42.068900  4948 configuration_utils.py:168] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 6,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I1016 20:16:42.948754  4948 modeling_utils.py:337] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at C:\\Users\\Grace\\.cache\\torch\\transformers\\35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "I1016 20:16:46.858669  4948 modeling_utils.py:405] Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "I1016 20:16:46.861668  4948 modeling_utils.py:408] Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name            module\n",
      "----------------------\n",
      "bert:embeddings\n",
      "bert:encoder\n",
      "bert:pooler\n",
      "dropout         Dropout(p=0.1, inplace=False)\n",
      "classifier      Linear(in_features=768, out_features=6, bias=True)\n"
     ]
    }
   ],
   "source": [
    "###---3.  在 BERT 之上加入新 layer 成下游任務模型\n",
    "# 載入一個可以做英文多分類任務的模型，n_class = 6\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers.modeling_bert import BertPreTrainedModel, BertModel\n",
    "\n",
    "PRETRAINED_MODEL_NAME = \"bert-base-cased\"\n",
    "NUM_LABELS = 6\n",
    "\n",
    "class BertForSequenceClassification(BertPreTrainedModel):\n",
    "\tdef __init__(self, config):\n",
    "\t\tsuper(BertForSequenceClassification, self).__init__(config)\n",
    "\t\tself.num_labels = config.num_labels\n",
    "\n",
    "\t\tself.bert = BertModel(config)  # 載入預訓練 BERT\n",
    "\t\tself.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\t\t# 簡單 linear 層\n",
    "\t\tself.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n",
    "\n",
    "\t\tself.init_weights()\n",
    "\n",
    "\tdef forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "\t\t# BERT 輸入就是 tokens, segments, masks\n",
    "\t\toutputs = self.bert(input_ids, token_type_ids, attention_mask)\n",
    "\t\t#_,pooled_output = self.bert(input_ids, token_type_ids, attention_mask)\n",
    "\t\t# 線性分類器將 dropout 後的 BERT repr. 轉成類別 logits\n",
    "\t\tpooled_output = outputs[1]\n",
    "\n",
    "\t\tpooled_output = self.dropout(pooled_output)\n",
    "\t\t# 線性分類器將 dropout 後的 BERT repr. 轉成類別 logits\n",
    "\t\tlogits = self.classifier(pooled_output)\n",
    "\t\tlogits = logits.sigmoid()\n",
    "\n",
    "\t\t# 輸入有 labels 的話直接計算 Cross Entropy 回傳，方便！\n",
    "\t\tif labels is not None:\n",
    "\t\t\t#  We are doing regression\n",
    "\t\t\t#注意对于BCELoss必须保证其输入的参数都位于0到1之间，无论是标签还是预测值，\n",
    "\t\t\t#如果不想让预测值必须位于0到1之间则可以采用BCEWithLogitsLoss损失函数。\n",
    "\t\t\tloss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "\t\t\t#loss_fct = torch.nn.BCELoss()\n",
    "\t\t\t#loss = loss_fct(m(logits.view(-1)), labels.view(-1))\n",
    "\t\t\tloss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "\t\t\treturn loss\n",
    "\t\t# 回傳各類別的 logits\n",
    "\t\treturn logits\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "\tPRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n",
    "\n",
    "\n",
    "# high-level 顯示此模型裡的 modules\n",
    "print(\"\"\"\n",
    "name            module\n",
    "----------------------\"\"\")\n",
    "for name, module in model.named_children():\n",
    "\tif name == \"bert\":\n",
    "\t\tfor n, _ in module.named_children():\n",
    "\t\t\tprint(f\"{name}:{n}\")\n",
    "\telse:\n",
    "\t\tprint(\"{:15} {}\".format(name, module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "tensor([[0.5847, 0.3990, 0.5506, 0.4000, 0.4802, 0.5224],\n",
      "        [0.6458, 0.4610, 0.5421, 0.3557, 0.4431, 0.5530],\n",
      "        [0.6184, 0.4146, 0.5475, 0.3818, 0.4435, 0.5472],\n",
      "        [0.5930, 0.4135, 0.5404, 0.4055, 0.4662, 0.5686],\n",
      "        [0.6176, 0.4275, 0.5462, 0.3710, 0.4514, 0.5697],\n",
      "        [0.6230, 0.4522, 0.5551, 0.3660, 0.4584, 0.5618],\n",
      "        [0.5799, 0.4119, 0.5684, 0.4185, 0.4583, 0.5401],\n",
      "        [0.6268, 0.4888, 0.5577, 0.3530, 0.4369, 0.5666],\n",
      "        [0.6092, 0.4498, 0.5796, 0.3761, 0.4647, 0.5659],\n",
      "        [0.6202, 0.4320, 0.5509, 0.3720, 0.4426, 0.5638],\n",
      "        [0.6411, 0.4709, 0.5719, 0.3537, 0.4367, 0.5702],\n",
      "        [0.6271, 0.4443, 0.5626, 0.3875, 0.4419, 0.5288],\n",
      "        [0.6032, 0.4258, 0.5757, 0.3923, 0.4530, 0.5526],\n",
      "        [0.6244, 0.4464, 0.5806, 0.3578, 0.4572, 0.5682],\n",
      "        [0.6019, 0.4468, 0.5688, 0.3919, 0.4585, 0.5638],\n",
      "        [0.6246, 0.4709, 0.5685, 0.3546, 0.4485, 0.5632],\n",
      "        [0.6160, 0.4416, 0.5597, 0.3859, 0.4448, 0.5639],\n",
      "        [0.6001, 0.4351, 0.5708, 0.3918, 0.4305, 0.5746],\n",
      "        [0.6026, 0.4158, 0.5565, 0.4310, 0.4614, 0.5318],\n",
      "        [0.5192, 0.3747, 0.5514, 0.4656, 0.4753, 0.5089],\n",
      "        [0.5488, 0.3941, 0.5436, 0.4475, 0.4636, 0.5300],\n",
      "        [0.6157, 0.4379, 0.5559, 0.3805, 0.4295, 0.5646],\n",
      "        [0.6176, 0.4313, 0.5634, 0.3975, 0.4196, 0.5634],\n",
      "        [0.5756, 0.3916, 0.5395, 0.4199, 0.4541, 0.5383],\n",
      "        [0.5834, 0.3904, 0.5504, 0.4341, 0.4466, 0.5235],\n",
      "        [0.5760, 0.4061, 0.5447, 0.4236, 0.4550, 0.5438],\n",
      "        [0.6271, 0.4519, 0.5467, 0.3649, 0.4401, 0.5624],\n",
      "        [0.6247, 0.5018, 0.5515, 0.3665, 0.4343, 0.5768],\n",
      "        [0.6111, 0.4219, 0.5446, 0.4004, 0.4226, 0.5644],\n",
      "        [0.5782, 0.3949, 0.5462, 0.4466, 0.4614, 0.5468],\n",
      "        [0.5443, 0.3774, 0.5422, 0.4372, 0.4730, 0.5177],\n",
      "        [0.5744, 0.4117, 0.5510, 0.4381, 0.4466, 0.5522],\n",
      "        [0.6152, 0.4412, 0.5458, 0.3736, 0.4448, 0.5675],\n",
      "        [0.5898, 0.4226, 0.5480, 0.4145, 0.4528, 0.5635],\n",
      "        [0.5837, 0.3851, 0.5358, 0.4280, 0.4671, 0.5340],\n",
      "        [0.5969, 0.3887, 0.5240, 0.4222, 0.4856, 0.5273],\n",
      "        [0.5891, 0.4352, 0.5543, 0.3865, 0.4329, 0.5443],\n",
      "        [0.6206, 0.4781, 0.5473, 0.3697, 0.4442, 0.5527],\n",
      "        [0.5904, 0.4190, 0.5372, 0.4255, 0.4801, 0.5224],\n",
      "        [0.6110, 0.4319, 0.5775, 0.3862, 0.4489, 0.5534],\n",
      "        [0.5800, 0.4294, 0.5462, 0.4037, 0.4559, 0.5525],\n",
      "        [0.6124, 0.4532, 0.5692, 0.3743, 0.4472, 0.5527],\n",
      "        [0.5696, 0.3994, 0.5423, 0.4190, 0.4742, 0.5227],\n",
      "        [0.6121, 0.4814, 0.5276, 0.3620, 0.4359, 0.5640],\n",
      "        [0.5657, 0.3991, 0.5383, 0.4406, 0.4603, 0.5426],\n",
      "        [0.6398, 0.4803, 0.5769, 0.3595, 0.4555, 0.5771],\n",
      "        [0.5268, 0.3864, 0.5515, 0.4562, 0.4650, 0.4902],\n",
      "        [0.5895, 0.4087, 0.5698, 0.4118, 0.4643, 0.5314],\n",
      "        [0.6283, 0.4425, 0.5502, 0.3636, 0.4522, 0.5668],\n",
      "        [0.5785, 0.4029, 0.5633, 0.4193, 0.4598, 0.5555],\n",
      "        [0.5202, 0.3905, 0.5325, 0.4792, 0.4794, 0.4914],\n",
      "        [0.5797, 0.4046, 0.5332, 0.4185, 0.4789, 0.5304],\n",
      "        [0.6326, 0.4677, 0.5598, 0.3508, 0.4572, 0.5680],\n",
      "        [0.5979, 0.4239, 0.5758, 0.4012, 0.4427, 0.5477],\n",
      "        [0.6232, 0.4523, 0.5535, 0.3617, 0.4564, 0.5689],\n",
      "        [0.5993, 0.4291, 0.5694, 0.4040, 0.4510, 0.5424],\n",
      "        [0.6155, 0.4390, 0.5525, 0.3728, 0.4612, 0.5643],\n",
      "        [0.5698, 0.3982, 0.5506, 0.4411, 0.4625, 0.5169],\n",
      "        [0.5924, 0.4335, 0.5728, 0.3979, 0.4524, 0.5540],\n",
      "        [0.6253, 0.4886, 0.5364, 0.3547, 0.4330, 0.5646],\n",
      "        [0.6018, 0.4411, 0.5449, 0.3748, 0.4447, 0.5687],\n",
      "        [0.6001, 0.4430, 0.5390, 0.3810, 0.4546, 0.5810],\n",
      "        [0.6025, 0.4709, 0.5492, 0.3710, 0.4451, 0.5803],\n",
      "        [0.6063, 0.4600, 0.5273, 0.3745, 0.4586, 0.5736]])\n",
      "labels:\n",
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 1.],\n",
      "        [0., 0., 1., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n",
      "total=384\n",
      "54\n",
      "predictions:\n",
      "tensor([[1.0000, 0.3990, 1.0000, 0.4000, 0.4802, 1.0000],\n",
      "        [1.0000, 0.4610, 1.0000, 0.3557, 0.4431, 1.0000],\n",
      "        [1.0000, 0.4146, 1.0000, 0.3818, 0.4435, 1.0000],\n",
      "        [1.0000, 0.4135, 1.0000, 0.4055, 0.4662, 1.0000],\n",
      "        [1.0000, 0.4275, 1.0000, 0.3710, 0.4514, 1.0000],\n",
      "        [1.0000, 0.4522, 1.0000, 0.3660, 0.4584, 1.0000],\n",
      "        [1.0000, 0.4119, 1.0000, 0.4185, 0.4583, 1.0000],\n",
      "        [1.0000, 0.4888, 1.0000, 0.3530, 0.4369, 1.0000],\n",
      "        [1.0000, 0.4498, 1.0000, 0.3761, 0.4647, 1.0000],\n",
      "        [1.0000, 0.4320, 1.0000, 0.3720, 0.4426, 1.0000],\n",
      "        [1.0000, 0.4709, 1.0000, 0.3537, 0.4367, 1.0000],\n",
      "        [1.0000, 0.4443, 1.0000, 0.3875, 0.4419, 1.0000],\n",
      "        [1.0000, 0.4258, 1.0000, 0.3923, 0.4530, 1.0000],\n",
      "        [1.0000, 0.4464, 1.0000, 0.3578, 0.4572, 1.0000],\n",
      "        [1.0000, 0.4468, 1.0000, 0.3919, 0.4585, 1.0000],\n",
      "        [1.0000, 0.4709, 1.0000, 0.3546, 0.4485, 1.0000],\n",
      "        [1.0000, 0.4416, 1.0000, 0.3859, 0.4448, 1.0000],\n",
      "        [1.0000, 0.4351, 1.0000, 0.3918, 0.4305, 1.0000],\n",
      "        [1.0000, 0.4158, 1.0000, 0.4310, 0.4614, 1.0000],\n",
      "        [1.0000, 0.3747, 1.0000, 0.4656, 0.4753, 1.0000],\n",
      "        [1.0000, 0.3941, 1.0000, 0.4475, 0.4636, 1.0000],\n",
      "        [1.0000, 0.4379, 1.0000, 0.3805, 0.4295, 1.0000],\n",
      "        [1.0000, 0.4313, 1.0000, 0.3975, 0.4196, 1.0000],\n",
      "        [1.0000, 0.3916, 1.0000, 0.4199, 0.4541, 1.0000],\n",
      "        [1.0000, 0.3904, 1.0000, 0.4341, 0.4466, 1.0000],\n",
      "        [1.0000, 0.4061, 1.0000, 0.4236, 0.4550, 1.0000],\n",
      "        [1.0000, 0.4519, 1.0000, 0.3649, 0.4401, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 0.3665, 0.4343, 1.0000],\n",
      "        [1.0000, 0.4219, 1.0000, 0.4004, 0.4226, 1.0000],\n",
      "        [1.0000, 0.3949, 1.0000, 0.4466, 0.4614, 1.0000],\n",
      "        [1.0000, 0.3774, 1.0000, 0.4372, 0.4730, 1.0000],\n",
      "        [1.0000, 0.4117, 1.0000, 0.4381, 0.4466, 1.0000],\n",
      "        [1.0000, 0.4412, 1.0000, 0.3736, 0.4448, 1.0000],\n",
      "        [1.0000, 0.4226, 1.0000, 0.4145, 0.4528, 1.0000],\n",
      "        [1.0000, 0.3851, 1.0000, 0.4280, 0.4671, 1.0000],\n",
      "        [1.0000, 0.3887, 1.0000, 0.4222, 0.4856, 1.0000],\n",
      "        [1.0000, 0.4352, 1.0000, 0.3865, 0.4329, 1.0000],\n",
      "        [1.0000, 0.4781, 1.0000, 0.3697, 0.4442, 1.0000],\n",
      "        [1.0000, 0.4190, 1.0000, 0.4255, 0.4801, 1.0000],\n",
      "        [1.0000, 0.4319, 1.0000, 0.3862, 0.4489, 1.0000],\n",
      "        [1.0000, 0.4294, 1.0000, 0.4037, 0.4559, 1.0000],\n",
      "        [1.0000, 0.4532, 1.0000, 0.3743, 0.4472, 1.0000],\n",
      "        [1.0000, 0.3994, 1.0000, 0.4190, 0.4742, 1.0000],\n",
      "        [1.0000, 0.4814, 1.0000, 0.3620, 0.4359, 1.0000],\n",
      "        [1.0000, 0.3991, 1.0000, 0.4406, 0.4603, 1.0000],\n",
      "        [1.0000, 0.4803, 1.0000, 0.3595, 0.4555, 1.0000],\n",
      "        [1.0000, 0.3864, 1.0000, 0.4562, 0.4650, 0.4902],\n",
      "        [1.0000, 0.4087, 1.0000, 0.4118, 0.4643, 1.0000],\n",
      "        [1.0000, 0.4425, 1.0000, 0.3636, 0.4522, 1.0000],\n",
      "        [1.0000, 0.4029, 1.0000, 0.4193, 0.4598, 1.0000],\n",
      "        [1.0000, 0.3905, 1.0000, 0.4792, 0.4794, 0.4914],\n",
      "        [1.0000, 0.4046, 1.0000, 0.4185, 0.4789, 1.0000],\n",
      "        [1.0000, 0.4677, 1.0000, 0.3508, 0.4572, 1.0000],\n",
      "        [1.0000, 0.4239, 1.0000, 0.4012, 0.4427, 1.0000],\n",
      "        [1.0000, 0.4523, 1.0000, 0.3617, 0.4564, 1.0000],\n",
      "        [1.0000, 0.4291, 1.0000, 0.4040, 0.4510, 1.0000],\n",
      "        [1.0000, 0.4390, 1.0000, 0.3728, 0.4612, 1.0000],\n",
      "        [1.0000, 0.3982, 1.0000, 0.4411, 0.4625, 1.0000],\n",
      "        [1.0000, 0.4335, 1.0000, 0.3979, 0.4524, 1.0000],\n",
      "        [1.0000, 0.4886, 1.0000, 0.3547, 0.4330, 1.0000],\n",
      "        [1.0000, 0.4411, 1.0000, 0.3748, 0.4447, 1.0000],\n",
      "        [1.0000, 0.4430, 1.0000, 0.3810, 0.4546, 1.0000],\n",
      "        [1.0000, 0.4709, 1.0000, 0.3710, 0.4451, 1.0000],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [1.0000, 0.4600, 1.0000, 0.3745, 0.4586, 1.0000]])\n",
      "classification acc: 0.140625\n"
     ]
    }
   ],
   "source": [
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "\tpredictions = None\n",
    "\tcorrect = 0\n",
    "\ttotal = 0\n",
    "\tthreshold = 0.5\n",
    "\tmodel.eval()  # 推論模式\n",
    "\twith torch.no_grad():\n",
    "\t\t# 遍巡整個資料集\n",
    "\t\tfor data in dataloader:\n",
    "\t\t\t# 將所有 tensors 移到 GPU 上\n",
    "\t\t\tif next(model.parameters()).is_cuda:\n",
    "\t\t\t\tdata = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "\t\t\t\t#data是三類tensor組合而成的list，最前面都是tokens_tensor，接著是segment_tensor，最後是label_tensor\n",
    "\t\t\t\n",
    "\t\t\t#print(\"data:\")\n",
    "\t\t\t#print(data)\t\n",
    "\t\t\t#print(\"*data[:3]:\")\n",
    "\t\t\t#print(*data[:3])\t            \n",
    "\t\t\toutputs = model(*data[:3])\t#*表示接受任意多个参数并将其放在一个元组中，每種tensor算一個element，故data有3個index\n",
    "\t\t\t#outputs為每筆資料預測的機率\n",
    "\t\t\t#print(\"outputs:\")\n",
    "\t\t\t#print(outputs)\n",
    "\n",
    "\t\t\t# 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n",
    "\t\t\t#logits = outputs[0]\n",
    "\t\t\tlogits = outputs          \n",
    "\t\t\tprint(logits)            \n",
    "\t\t\t#pred = torch.sigmoid(logits.data)\n",
    "\t\t\t#由于每一个样本可能属于多个类别，因此不能直接根据argmax(output,1)去直接取概率最大的输出值作为其类别，\n",
    "\t\t\t#而是应该设置一个阈值（默认0.5）来对output进行过滤，得到样本所属的multi-class。\n",
    "\t\t\tfor item in logits:\n",
    "\t\t\t\tfor i in range(len(item)):\t#傳回來的logits若高於threshold則代表有該標籤，設為1\n",
    "\t\t\t\t\tif item[i] >= threshold:\n",
    "\t\t\t\t\t\titem[i] = 1\n",
    "\t\t\tpred = logits\n",
    "\t\t\t#print(pred)\n",
    "\t\t\t# 用來計算訓練集的分類準確率\n",
    "\t\t\tif compute_acc:\n",
    "\t\t\t\tlabels = data[3]\t#label放在最後一個\n",
    "\t\t\t\tprint(\"labels:\")\n",
    "\t\t\t\tprint(labels)\n",
    "\t\t\t\ttotal += labels.size(0)*6\t#會印出64，因為每個batch取64個documents\n",
    "\t\t\t\tprint(\"total=\"+str(total))\n",
    "\t\t\t\tcorrect += (pred == labels).sum().item()\n",
    "\t\t\t\tprint(correct)\n",
    "\t\t\t# 將當前 batch 記錄下來\n",
    "\t\t\tif predictions is None:\n",
    "\t\t\t\tpredictions = pred\n",
    "\t\t\telse:\n",
    "\t\t\t\tpredictions = torch.cat((predictions, pred))\n",
    "\t\t\tprint('predictions:')\n",
    "\t\t\tprint(predictions)\n",
    "\t\t\tbreak\n",
    "\t\n",
    "\tif compute_acc:\n",
    "\t\tacc = correct / total\n",
    "\t\treturn predictions, acc\n",
    "\treturn predictions\n",
    "\t\n",
    "# 讓模型跑在 GPU 上並取得訓練集的分類準確率﹝初始化狀態的測試﹞\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)\t#Performs Tensor dtype and/or device conversion\n",
    "_, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "print(\"classification acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "整個分類模型的參數量：108314886\n",
      "線性分類器的參數量：4614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#算算整個分類模型以及裡頭的簡單分類器有多少參數\n",
    "def get_learnable_params(module):\n",
    "\treturn [p for p in module.parameters() if p.requires_grad]\n",
    "\t \n",
    "model_params = get_learnable_params(model)\n",
    "clf_params = get_learnable_params(model.classifier)\n",
    "\n",
    "print(f\"\"\"\n",
    "整個分類模型的參數量：{sum(p.numel() for p in model_params)}\n",
    "線性分類器的參數量：{sum(p.numel() for p in clf_params)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###---4. 訓練該下游任務模型\n",
    "# train mode\n",
    "model.train()\n",
    "\n",
    "# 使用 Adam Optim 更新整個分類模型的參數\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-2)\n",
    "\n",
    "\n",
    "EPOCHS = 60  # 幸運數字\n",
    "for epoch in range(EPOCHS):\n",
    "\t\n",
    "\trunning_loss = 0.0\n",
    "\tfor data in trainloader:\n",
    "\t\t\n",
    "\t\ttokens_tensors, segments_tensors, \\\n",
    "\t\tmasks_tensors, labels = [t.to(device) for t in data]\n",
    "\n",
    "\t\t# 將參數梯度歸零\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\t\n",
    "\t\t# forward pass\n",
    "\t\toutputs = model(input_ids=tokens_tensors, \n",
    "\t\t\t\t\t\ttoken_type_ids=segments_tensors, \n",
    "\t\t\t\t\t\tattention_mask=masks_tensors, \n",
    "\t\t\t\t\t\tlabels=labels)\n",
    "\t\t#print('outputs:')\n",
    "\t\t#print(outputs)\n",
    "\t\t#loss = outputs[0]\n",
    "\t\tloss = outputs\n",
    "\t\t# backward\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\n",
    "\t\t# 紀錄當前 batch loss\n",
    "\t\trunning_loss += loss.item()\n",
    "\t\t\n",
    "\t# 計算分類準確率\n",
    "\t_, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "\n",
    "\tprint('[epoch %d] loss: %.3f, acc: %.3f' %\n",
    "\t\t  (epoch + 1, running_loss, acc))\n",
    "\n",
    "torch.save(model, 'paper_predict.pkl')  # 保存整个网络\n",
    "torch.save(model.state_dict(), 'paper_predict_params.pkl')   # 只保存网络中的参数 (速度快, 占内存少)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
